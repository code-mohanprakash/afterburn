{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Afterburn","text":"<p>Post-training diagnostics for LLMs \u2014 what did fine-tuning actually do to your model?</p> <p>Afterburn takes two model checkpoints (base + post-trained) and produces a diagnostic report covering weight diffs, behavioural shifts, and reward hacking detection.</p> <p>Most evaluation tools tell you benchmark scores went up or down. Afterburn tells you why.</p>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>Weight Diff Analysis \u2014 L2, cosine, Frobenius, SVD decomposition, spectral alpha, Marchenko-Pastur law, behavioral vectors, attention head importance, LayerNorm shifts, embedding drift</li> <li>Behavioral Shift Detection \u2014 Output length changes (Mann-Whitney U, Cohen's d), reasoning strategy classification, format compliance, chain-of-thought depth, diversity (EAD), token divergence (JSD), NLI-enhanced semantic analysis</li> <li>Reward Hacking Detection \u2014 Length bias, format gaming, strategy collapse, sycophancy (40 adversarial probes + NLI), composite risk score (0-100)</li> <li>Reports \u2014 Interactive HTML (Plotly), JSON, Markdown, PDF</li> </ul>"},{"location":"#quick-start","title":"Quick Start","text":"<pre><code>pip install afterburn\n\nafterburn diagnose \\\n  --base Qwen/Qwen2.5-0.5B \\\n  --trained Qwen/Qwen2.5-0.5B-Instruct \\\n  --method sft \\\n  -o report.html\n</code></pre> <pre><code>from afterburn import Diagnoser\n\nreport = Diagnoser(\n    base_model=\"Qwen/Qwen2.5-0.5B\",\n    trained_model=\"Qwen/Qwen2.5-0.5B-Instruct\",\n    method=\"sft\",\n).run()\n\nprint(report.summary)\nreport.save(\"report.html\")\n</code></pre>"},{"location":"contributing/","title":"Contributing","text":""},{"location":"contributing/#development-setup","title":"Development Setup","text":"<pre><code>git clone https://github.com/code-mohanprakash/afterburn.git\ncd afterburn\npip install -e \".[dev]\"\n</code></pre>"},{"location":"contributing/#running-tests","title":"Running Tests","text":"<pre><code>pytest tests/ -v\npytest tests/ --cov=afterburn --cov-report=term-missing\n</code></pre>"},{"location":"contributing/#code-style","title":"Code Style","text":"<pre><code>ruff check src/ tests/\nruff format src/ tests/\n</code></pre>"},{"location":"contributing/#type-checking","title":"Type Checking","text":"<pre><code>mypy src/afterburn/ --ignore-missing-imports\n</code></pre>"},{"location":"contributing/#architecture","title":"Architecture","text":"<pre><code>src/afterburn/\n\u251c\u2500\u2500 loading/        # Model loading, safetensors, LoRA\n\u251c\u2500\u2500 weight_diff/    # Layer-by-layer weight comparison\n\u251c\u2500\u2500 behaviour/      # Behavioral shift analysis\n\u251c\u2500\u2500 reward_hack/    # Reward hacking detection\n\u251c\u2500\u2500 prompts/        # Prompt suites + inference runner\n\u251c\u2500\u2500 report/         # HTML/JSON/MD/PDF report generation\n\u251c\u2500\u2500 nli.py          # Shared NLI model (cross-encoder)\n\u251c\u2500\u2500 diagnoser.py    # Top-level orchestrator\n\u2514\u2500\u2500 types.py        # Shared dataclasses and enums\n</code></pre>"},{"location":"contributing/#adding-a-reward-hack-detector","title":"Adding a Reward Hack Detector","text":"<ol> <li>Create <code>src/afterburn/reward_hack/my_detector.py</code></li> <li>Return a result dataclass (add to <code>types.py</code>)</li> <li>Wire into <code>detector.py</code> orchestrator</li> <li>Add to <code>risk_score.py</code> composite calculation</li> <li>Add tests in <code>tests/test_reward_hack/</code></li> </ol>"},{"location":"contributing/#adding-a-prompt-suite","title":"Adding a Prompt Suite","text":"<p>Create a YAML file:</p> <pre><code>name: \"my-domain\"\ncategory: \"custom\"\nprompts:\n  - id: \"q1\"\n    text: \"Your prompt\"\n    expected_answer: \"Expected answer\"\n    difficulty: \"medium\"\n    tags: [\"domain\"]\n</code></pre>"},{"location":"api/diagnoser/","title":"Diagnoser API","text":"<p>The <code>Diagnoser</code> class is the main entry point for running diagnostics.</p>"},{"location":"api/diagnoser/#constructor","title":"Constructor","text":"<pre><code>from afterburn import Diagnoser\n\ndiag = Diagnoser(\n    base_model=\"meta-llama/Llama-3.1-8B\",\n    trained_model=\"my-org/Llama-3.1-8B-SFT\",\n    method=\"sft\",\n)\n</code></pre>"},{"location":"api/diagnoser/#parameters","title":"Parameters","text":"Parameter Type Default Description <code>base_model</code> <code>str</code> required HuggingFace model ID or local path to the base model <code>trained_model</code> <code>str</code> required HuggingFace model ID or local path to the trained model <code>method</code> <code>str</code> <code>\"unknown\"</code> Training method: <code>sft</code>, <code>dpo</code>, <code>rlhf</code>, <code>rlvr</code>, <code>grpo</code>, <code>lora</code>, <code>qlora</code> <code>suites</code> <code>list[str]</code> <code>None</code> Prompt suites to run. Default: <code>[\"math\", \"code\", \"reasoning\", \"safety\"]</code> <code>config_path</code> <code>str</code> <code>None</code> Path to <code>.afterburn.yaml</code> configuration file <code>device</code> <code>str</code> <code>None</code> Force device: <code>cuda</code>, <code>mps</code>, <code>cpu</code>. Default: auto-detect <code>modules</code> <code>list[str]</code> <code>None</code> Modules to run: <code>weight_diff</code>, <code>behaviour</code>, <code>reward_hack</code>. Default: all <code>collect_logits</code> <code>bool</code> <code>False</code> Collect token-level probabilities for JSD analysis"},{"location":"api/diagnoser/#methods","title":"Methods","text":""},{"location":"api/diagnoser/#run-diagnosticreport","title":"<code>run() -&gt; DiagnosticReport</code>","text":"<p>Run full diagnostic analysis (weight diff + behaviour + reward hack).</p> <pre><code>report = diag.run()\nprint(report.summary)\nprint(f\"Risk score: {report.hack_score:.0f}/100\")\nreport.save(\"report.html\")\n</code></pre>"},{"location":"api/diagnoser/#run_weight_diff-weightdiffresult","title":"<code>run_weight_diff() -&gt; WeightDiffResult</code>","text":"<p>Run weight diff analysis only. No inference needed \u2014 compares weights directly.</p> <pre><code>wd = diag.run_weight_diff()\nfor layer in wd.top_changed_layers:\n    print(f\"{layer.layer_name}: {layer.relative_change:.4f}\")\n</code></pre>"},{"location":"api/diagnoser/#run_behaviour-behaviourresult","title":"<code>run_behaviour() -&gt; BehaviourResult</code>","text":"<p>Run behavioural analysis only. Loads each model sequentially for inference.</p> <pre><code>bh = diag.run_behaviour()\nprint(f\"Length change: {bh.length_analysis.mean_diff:+.1f} tokens\")\nprint(f\"Strategy shift: {bh.strategy_analysis.dominant_shift}\")\n</code></pre>"},{"location":"api/diagnoser/#run_hack_check-rewardhackresult","title":"<code>run_hack_check() -&gt; RewardHackResult</code>","text":"<p>Run reward hack detection. Requires behaviour results (runs inference if needed).</p> <pre><code>rh = diag.run_hack_check()\nprint(f\"Composite score: {rh.composite_score:.0f}/100 ({rh.risk_level.value})\")\nfor flag in rh.flags:\n    print(f\"  - {flag}\")\n</code></pre>"},{"location":"api/diagnoser/#diagnosticreport","title":"DiagnosticReport","text":"<p>The top-level report container returned by <code>run()</code>.</p> Field Type Description <code>model_pair</code> <code>ModelPair</code> Base and trained model identifiers <code>weight_diff</code> <code>WeightDiffResult \\| None</code> Weight diff results (if run) <code>behaviour</code> <code>BehaviourResult \\| None</code> Behaviour results (if run) <code>reward_hack</code> <code>RewardHackResult \\| None</code> Reward hack results (if run) <code>summary</code> <code>str</code> Plain-English executive summary <code>hack_score</code> <code>float</code> Composite reward hack score (0-100) <code>recommendations</code> <code>list[str]</code> Actionable recommendations"},{"location":"api/diagnoser/#methods_1","title":"Methods","text":"Method Description <code>save(path)</code> Save report to file (format auto-detected from extension) <code>to_json()</code> Return report as JSON-serializable dict"},{"location":"api/diagnoser/#lower-level-apis","title":"Lower-Level APIs","text":""},{"location":"api/diagnoser/#weightdiffengine","title":"WeightDiffEngine","text":"<p>For direct weight comparison without the orchestrator:</p> <pre><code>from afterburn.weight_diff.engine import WeightDiffEngine\nfrom afterburn.device import auto_detect_device\nfrom afterburn.types import ModelPair\n\npair = ModelPair(base_model=\"base-path\", trained_model=\"trained-path\")\nengine = WeightDiffEngine(pair, auto_detect_device())\nresult = engine.run()\n</code></pre>"},{"location":"api/diagnoser/#behaviouranalyser","title":"BehaviourAnalyser","text":"<pre><code>from afterburn.behaviour.analyser import BehaviourAnalyser\nfrom afterburn.device import auto_detect_device\nfrom afterburn.types import ModelPair\n\npair = ModelPair(base_model=\"base-path\", trained_model=\"trained-path\")\nanalyser = BehaviourAnalyser(pair, auto_detect_device(), suites=[\"math\"])\nresult = analyser.run()\n</code></pre>"},{"location":"api/diagnoser/#rewardhackdetector","title":"RewardHackDetector","text":"<pre><code>from afterburn.reward_hack.detector import RewardHackDetector\n\ndetector = RewardHackDetector()\nresult = detector.detect(behaviour_result, training_method=\"sft\")\n</code></pre>"},{"location":"api/types/","title":"Types Reference","text":"<p>All types are frozen dataclasses defined in <code>afterburn.types</code>.</p>"},{"location":"api/types/#core-types","title":"Core Types","text":""},{"location":"api/types/#modelpair","title":"ModelPair","text":"<pre><code>@dataclass(frozen=True)\nclass ModelPair:\n    base_model: str          # HuggingFace ID or local path\n    trained_model: str       # HuggingFace ID or local path\n    method: TrainingMethod   # Training method used\n</code></pre>"},{"location":"api/types/#diagnosticreport","title":"DiagnosticReport","text":"<p>Top-level report container. See Diagnoser API.</p>"},{"location":"api/types/#weight-diff-types","title":"Weight Diff Types","text":""},{"location":"api/types/#layerdiff","title":"LayerDiff","text":"<p>Per-layer weight comparison metrics.</p> Field Type Description <code>layer_name</code> <code>str</code> Layer identifier (e.g. <code>layer_5</code>) <code>layer_index</code> <code>int</code> Numeric layer index <code>l2_norm</code> <code>float</code> L2 norm of weight difference <code>cosine_similarity</code> <code>float</code> Cosine similarity (1.0 = unchanged) <code>frobenius_norm</code> <code>float</code> Frobenius norm of difference <code>relative_change</code> <code>float</code> Change relative to base magnitude <code>param_count</code> <code>int</code> Number of parameters in this layer <code>svd_top_singular_values</code> <code>tuple[float, ...] \\| None</code> Top singular values of the diff <code>svd_effective_rank</code> <code>int \\| None</code> Effective rank (90% energy) <code>svd_concentration_ratio</code> <code>float \\| None</code> Energy in top-1 SV / total <code>svd_stable_rank</code> <code>float \\| None</code> Frobenius^2 / spectral^2 <code>spectral_alpha</code> <code>float \\| None</code> Power-law exponent (2-4 = healthy) <code>spectral_alpha_quality</code> <code>str \\| None</code> Quality assessment: good/fair/poor/unstable <code>mp_sigma_sq</code> <code>float \\| None</code> Marchenko-Pastur noise variance <code>mp_num_spikes</code> <code>int \\| None</code> Eigenvalues above MP upper edge <code>mp_bulk_fraction</code> <code>float \\| None</code> Fraction within MP bulk <code>mp_kl_divergence</code> <code>float \\| None</code> KL divergence from theoretical MP"},{"location":"api/types/#attentionheadscore","title":"AttentionHeadScore","text":"Field Type Description <code>layer_index</code> <code>int</code> Layer number <code>head_index</code> <code>int</code> Head number <code>base_importance</code> <code>float</code> Base model head importance <code>trained_importance</code> <code>float</code> Trained model head importance <code>importance_delta</code> <code>float</code> Change in importance"},{"location":"api/types/#layernormshift","title":"LayerNormShift","text":"Field Type Description <code>layer_name</code> <code>str</code> Layer identifier <code>layer_index</code> <code>int</code> Numeric layer index <code>gamma_shift</code> <code>float</code> Mean absolute change in scale (gamma) <code>beta_shift</code> <code>float</code> Mean absolute change in bias (beta) <code>total_shift</code> <code>float</code> Combined relative shift <code>is_significant</code> <code>bool</code> Whether shift exceeds threshold"},{"location":"api/types/#embeddingdrift","title":"EmbeddingDrift","text":"Field Type Description <code>input_embedding_l2</code> <code>float</code> L2 distance of input embeddings <code>input_embedding_cosine</code> <code>float</code> Cosine similarity of input embeddings <code>output_embedding_l2</code> <code>float \\| None</code> L2 distance of output embeddings <code>output_embedding_cosine</code> <code>float \\| None</code> Cosine similarity of output embeddings <code>top_drifted_tokens</code> <code>list[tuple[int, float]]</code> Most-changed token IDs with drift magnitude"},{"location":"api/types/#behavioralvector","title":"BehavioralVector","text":"Field Type Description <code>layer_name</code> <code>str</code> Layer identifier <code>singular_value</code> <code>float</code> Magnitude of this direction <code>direction_index</code> <code>int</code> Rank (0 = dominant) <code>explained_variance_ratio</code> <code>float</code> Fraction of total variance explained"},{"location":"api/types/#weightdiffresult","title":"WeightDiffResult","text":"Field Type Description <code>layer_diffs</code> <code>list[LayerDiff]</code> All layer diffs <code>attention_heads</code> <code>list[AttentionHeadScore]</code> Per-head scores <code>layernorm_shifts</code> <code>list[LayerNormShift]</code> LayerNorm parameter shifts <code>embedding_drift</code> <code>EmbeddingDrift</code> Embedding layer movement <code>lora_analysis</code> <code>dict \\| None</code> LoRA adapter analysis (if detected) <code>total_param_count</code> <code>int</code> Total parameters compared <code>changed_param_count</code> <code>int</code> Parameters with measurable change <code>behavioral_vectors</code> <code>list[BehavioralVector]</code> Principal change directions <code>direction_coherence</code> <code>float</code> Cross-layer direction alignment (0-1) <p>Properties: <code>top_changed_layers</code>, <code>change_concentration</code></p>"},{"location":"api/types/#behaviour-types","title":"Behaviour Types","text":""},{"location":"api/types/#lengthanalysis","title":"LengthAnalysis","text":"Field Type Description <code>base_mean</code> <code>float</code> Mean output length (base model) <code>trained_mean</code> <code>float</code> Mean output length (trained model) <code>mean_diff</code> <code>float</code> Difference in means <code>cohens_d</code> <code>float</code> Effect size (0.2=small, 0.5=medium, 0.8=large) <code>p_value</code> <code>float</code> Mann-Whitney U test p-value <code>is_significant</code> <code>bool</code> p &lt; 0.05 and |d| &gt; 0.2"},{"location":"api/types/#formatanalysis","title":"FormatAnalysis","text":"Field Type Description <code>base_format_rate</code> <code>float</code> Format pattern match rate (base) <code>trained_format_rate</code> <code>float</code> Format pattern match rate (trained) <code>format_increase</code> <code>float</code> Rate increase <code>patterns_detected</code> <code>dict[str, dict]</code> Per-pattern base/trained rates"},{"location":"api/types/#strategyshiftanalysis","title":"StrategyShiftAnalysis","text":"Field Type Description <code>base_distribution</code> <code>dict[str, float]</code> Strategy frequency distribution (base) <code>trained_distribution</code> <code>dict[str, float]</code> Strategy frequency distribution (trained) <code>dominant_shift</code> <code>str</code> Most prominent strategy change <code>base_entropy</code> <code>float</code> Shannon entropy of base distribution <code>trained_entropy</code> <code>float</code> Shannon entropy of trained distribution <code>entropy_change</code> <code>float</code> Entropy difference"},{"location":"api/types/#chainofthoughtanalysis","title":"ChainOfThoughtAnalysis","text":"Field Type Description <code>base_avg_steps</code> <code>float</code> Average reasoning steps (base) <code>trained_avg_steps</code> <code>float</code> Average reasoning steps (trained) <code>step_count_change</code> <code>float</code> Change in step count <code>base_avg_depth</code> <code>float</code> Average reasoning depth (base) <code>trained_avg_depth</code> <code>float</code> Average reasoning depth (trained) <code>depth_change</code> <code>float</code> Change in depth"},{"location":"api/types/#diversityanalysis","title":"DiversityAnalysis","text":"Field Type Description <code>base_ead</code> <code>dict[int, float]</code> EAD scores per n-gram level (base) <code>trained_ead</code> <code>dict[int, float]</code> EAD scores per n-gram level (trained) <code>base_diversity_score</code> <code>float</code> Mean EAD across n=1..5 (base) <code>trained_diversity_score</code> <code>float</code> Mean EAD across n=1..5 (trained) <code>diversity_change</code> <code>float</code> Change in diversity score"},{"location":"api/types/#tokendivergenceanalysis","title":"TokenDivergenceAnalysis","text":"Field Type Description <code>mean_jsd</code> <code>float</code> Mean Jensen-Shannon Divergence [0, 1] <code>per_prompt_jsd</code> <code>list[float]</code> JSD values per prompt <code>top_divergent_prompts</code> <code>list[tuple[str, float]]</code> Most divergent (prompt_id, JSD) <code>has_token_probs</code> <code>bool</code> Whether token probability data was available"},{"location":"api/types/#reward-hack-types","title":"Reward Hack Types","text":""},{"location":"api/types/#rewardhackresult","title":"RewardHackResult","text":"Field Type Description <code>composite_score</code> <code>float</code> Weighted risk score (0-100) <code>risk_level</code> <code>RiskLevel</code> LOW / MODERATE / HIGH / CRITICAL <code>flags</code> <code>list[str]</code> Human-readable warning flags <code>length_bias</code> <code>LengthBiasResult</code> Length bias detection result <code>format_gaming</code> <code>FormatGamingResult</code> Format gaming detection result <code>strategy_collapse</code> <code>StrategyCollapseResult</code> Strategy collapse result <code>sycophancy</code> <code>SycophancyResult</code> Sycophancy detection result"},{"location":"api/types/#sub-detector-results","title":"Sub-detector Results","text":"<p>Each sub-detector result has at minimum:</p> Field Type Description <code>score</code> <code>float</code> Individual detector score (0-100) <code>is_flagged</code> <code>bool</code> Whether this detector triggered <code>detail</code> <code>str</code> Human-readable explanation"},{"location":"api/types/#enums","title":"Enums","text":"Enum Values <code>TrainingMethod</code> <code>sft</code>, <code>dpo</code>, <code>rlhf</code>, <code>rlvr</code>, <code>grpo</code>, <code>lora</code>, <code>qlora</code>, <code>unknown</code> <code>ReportFormat</code> <code>html</code>, <code>markdown</code>, <code>pdf</code>, <code>json</code> <code>RiskLevel</code> <code>low</code>, <code>moderate</code>, <code>high</code>, <code>critical</code> <code>ReasoningStrategy</code> <code>direct_answer</code>, <code>step_by_step</code>, <code>code_assisted</code>, <code>chain_of_thought</code>, <code>tool_use</code>, <code>unknown</code>"},{"location":"getting-started/configuration/","title":"Configuration","text":"<p>Create <code>.afterburn.yaml</code> in your project root:</p> <pre><code>device: auto          # auto | cuda | mps | cpu\n\nbehaviour:\n  suites: [math, code, reasoning, safety]\n  max_new_tokens: 512\n  batch_size: 4\n  temperature: 0.0\n\nreward_hack:\n  weights:\n    length_bias: 0.25\n    format_gaming: 0.30\n    strategy_collapse: 0.20\n    sycophancy: 0.25\n  thresholds:\n    length_bias_cohens_d: 0.5\n    format_increase_ratio: 2.0\n    strategy_entropy_drop: 0.3\n    sycophancy_increase: 0.15\n</code></pre>"},{"location":"getting-started/configuration/#custom-prompt-suites","title":"Custom Prompt Suites","text":"<pre><code>name: \"my-domain\"\ncategory: \"custom\"\nprompts:\n  - id: \"q1\"\n    text: \"Explain quantum entanglement\"\n    expected_answer: \"...\"\n    difficulty: \"hard\"\n    tags: [\"physics\"]\n</code></pre> <pre><code>afterburn diagnose --suites my-suite.yaml\n</code></pre>"},{"location":"getting-started/installation/","title":"Installation","text":""},{"location":"getting-started/installation/#from-pypi","title":"From PyPI","text":"<pre><code>pip install afterburn\n</code></pre>"},{"location":"getting-started/installation/#from-source-development","title":"From Source (development)","text":"<pre><code>git clone https://github.com/code-mohanprakash/afterburn.git\ncd afterburn\npip install -e \".[dev]\"\n</code></pre>"},{"location":"getting-started/installation/#optional-dependencies","title":"Optional Dependencies","text":"<pre><code># PDF export\npip install afterburn[pdf]\n\n# Semantic diversity (SBERT)\npip install afterburn[semantic]\n\n# NLI-enhanced analysis\npip install afterburn[nli]\n</code></pre>"},{"location":"getting-started/installation/#requirements","title":"Requirements","text":"<ul> <li>Python 3.10+</li> <li>PyTorch 2.0+</li> <li>GPU recommended but not required (CUDA, MPS, CPU all supported)</li> </ul>"},{"location":"getting-started/quickstart/","title":"Quick Start","text":""},{"location":"getting-started/quickstart/#cli-usage","title":"CLI Usage","text":"<pre><code># Full diagnostic report\nafterburn diagnose \\\n  --base meta-llama/Llama-3.1-8B \\\n  --trained my-org/Llama-3.1-8B-SFT \\\n  --method sft \\\n  -o report.html\n\n# Individual analyses\nafterburn weight-diff --base &lt;model&gt; --trained &lt;model&gt; -o weights.json\nafterburn behaviour --base &lt;model&gt; --trained &lt;model&gt; -o behaviour.json\nafterburn hack-check --base &lt;model&gt; --trained &lt;model&gt; -o hacking.json\n</code></pre>"},{"location":"getting-started/quickstart/#python-api","title":"Python API","text":"<pre><code>from afterburn import Diagnoser\n\ndiag = Diagnoser(\n    base_model=\"meta-llama/Llama-3.1-8B\",\n    trained_model=\"my-org/Llama-3.1-8B-SFT\",\n    method=\"sft\",\n)\n\nreport = diag.run()\n\n# Access results programmatically\nprint(f\"Top changed layer: {report.top_changed_layers[0].layer_name}\")\nprint(f\"Reward hack risk: {report.hack_score:.0f}/100\")\nprint(report.summary)\n\n# Save in multiple formats\nreport.save(\"report.html\")\nreport.save(\"report.json\")\nreport.save(\"report.md\")\n</code></pre>"},{"location":"getting-started/quickstart/#understanding-the-output","title":"Understanding the Output","text":""},{"location":"getting-started/quickstart/#weight-diff","title":"Weight Diff","text":"<p>Each layer gets metrics including L2 norm, cosine similarity, Frobenius norm, relative change, SVD decomposition, spectral alpha, and Marchenko-Pastur law comparison.</p>"},{"location":"getting-started/quickstart/#reward-hack-score","title":"Reward Hack Score","text":"<p>A composite score from 0-100: - 0-25: LOW risk \u2014 training looks clean - 26-50: MODERATE \u2014 some patterns worth investigating - 51-75: HIGH \u2014 clear reward hacking indicators - 76-100: CRITICAL \u2014 severe reward gaming detected</p>"},{"location":"guide/behaviour/","title":"Behavioral Analysis","text":"<p>Runs the same prompts through both models and compares outputs statistically.</p>"},{"location":"guide/behaviour/#analyses","title":"Analyses","text":"<ul> <li>Length Distribution \u2014 Mann-Whitney U test, Cohen's d, skewness, kurtosis, percentiles</li> <li>Format Compliance \u2014 Code blocks, LaTeX, markdown headers, bullet lists, tables, thinking tags</li> <li>Reasoning Strategy \u2014 Classification: direct answer, step-by-step, code-assisted, chain-of-thought, tool use</li> <li>Chain-of-Thought \u2014 Step counting, depth analysis, self-correction rate, verification rate</li> <li>Calibration \u2014 Expected Calibration Error (ECE), reliability diagrams, overconfidence</li> <li>Diversity \u2014 EAD (Expectation-Adjusted Distinct n-grams), optional SBERT semantic diversity</li> <li>Token Divergence \u2014 Jensen-Shannon Divergence on token probability distributions</li> </ul>"},{"location":"guide/behaviour/#nli-enhancement","title":"NLI Enhancement","text":"<p>When <code>transformers</code> is installed, Afterburn loads <code>cross-encoder/nli-deberta-v3-small</code> for: - Semantic agreement/pushback detection in sycophancy analysis - Answer verification via entailment checking - Zero-shot reasoning strategy classification as a tiebreaker</p>"},{"location":"guide/deployment/","title":"Production Deployment Guide","text":"<p>This guide covers deploying Afterburn in production environments for automated post-training diagnostics.</p>"},{"location":"guide/deployment/#system-requirements","title":"System Requirements","text":"<p>Memory and compute requirements vary by model size:</p> Model Size RAM (CPU) VRAM (GPU) Recommended CPU Recommended GPU 0.5B - 1B 8 GB 4 GB 4+ cores T4 / RTX 3060 7B 32 GB 16 GB 8+ cores A10 / RTX 4090 13B 64 GB 24 GB 16+ cores A100 40GB 70B+ 256 GB 80 GB 32+ cores A100 80GB x2 <p>Notes: - CPU-only mode requires 2-3x more RAM than listed above - Add 20% overhead for analysis artifacts and reports - SSD storage recommended for model caching (100+ GB free space)</p>"},{"location":"guide/deployment/#docker","title":"Docker","text":""},{"location":"guide/deployment/#dockerfile","title":"Dockerfile","text":"<pre><code>FROM python:3.11-slim\n\n# Install system dependencies\nRUN apt-get update &amp;&amp; apt-get install -y \\\n    git \\\n    &amp;&amp; rm -rf /var/lib/apt/lists/*\n\n# Create non-root user\nRUN useradd -m -u 1000 afterburn\nWORKDIR /app\nRUN chown afterburn:afterburn /app\n\nUSER afterburn\n\n# Install afterburn\nCOPY --chown=afterburn:afterburn . /app\nRUN pip install --no-cache-dir -e .\n\n# Set HuggingFace cache directory\nENV HF_HOME=/app/.cache/huggingface\nENV TRANSFORMERS_CACHE=/app/.cache/huggingface\n\nENTRYPOINT [\"afterburn\"]\nCMD [\"--help\"]\n</code></pre>"},{"location":"guide/deployment/#docker-composeyml","title":"docker-compose.yml","text":"<pre><code>version: '3.8'\n\nservices:\n  afterburn:\n    build: .\n    volumes:\n      - ./models:/app/models\n      - ./reports:/app/reports\n      - hf-cache:/app/.cache/huggingface\n    environment:\n      - HF_TOKEN=${HF_TOKEN}\n      - CUDA_VISIBLE_DEVICES=0\n    deploy:\n      resources:\n        reservations:\n          devices:\n            - driver: nvidia\n              count: 1\n              capabilities: [gpu]\n    command: &gt;\n      diagnose\n      --base /app/models/base\n      --trained /app/models/trained\n      --output /app/reports/report.html\n      --log-format json\n\nvolumes:\n  hf-cache:\n</code></pre> <p>Usage: <pre><code>export HF_TOKEN=hf_xxx\ndocker-compose up\n</code></pre></p>"},{"location":"guide/deployment/#memory-sizing","title":"Memory Sizing","text":""},{"location":"guide/deployment/#formula","title":"Formula","text":"<pre><code>RAM (GB) = (Model_Params \u00d7 Precision_Bytes \u00d7 Safety_Factor) / 1e9\n\n# For analysis:\nTotal_RAM = Base_Model_RAM + Trained_Model_RAM + Analysis_Overhead\n</code></pre> <p>Examples: - 7B model (fp16): 7B \u00d7 2 bytes \u00d7 1.2 = ~17 GB per model \u2192 34 GB + 4 GB overhead = 38 GB total - 13B model (fp16): 13B \u00d7 2 bytes \u00d7 1.2 = ~31 GB per model \u2192 62 GB + 6 GB overhead = 68 GB total</p> <p>Precision options: - <code>fp16</code> / <code>bfloat16</code>: 2 bytes per parameter - <code>fp32</code>: 4 bytes per parameter - <code>int8</code>: 1 byte per parameter (if quantized)</p> <p>Safety factor (1.2) accounts for: - Gradient computation during analysis - Temporary tensors and intermediate results - Python runtime overhead</p>"},{"location":"guide/deployment/#cicd-integration","title":"CI/CD Integration","text":""},{"location":"guide/deployment/#github-actions-example","title":"GitHub Actions Example","text":"<p>Automated post-training validation in CI pipeline:</p> <pre><code>name: Post-Training Validation\n\non:\n  push:\n    branches: [main]\n    paths:\n      - 'models/**'\n      - 'training/**'\n\njobs:\n  afterburn-check:\n    runs-on: ubuntu-latest\n    container:\n      image: nvidia/cuda:12.1.0-runtime-ubuntu22.04\n\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Setup Python\n        uses: actions/setup-python@v4\n        with:\n          python-version: '3.11'\n\n      - name: Install Afterburn\n        run: pip install afterburn\n\n      - name: Download Models\n        env:\n          HF_TOKEN: ${{ secrets.HF_TOKEN }}\n        run: |\n          huggingface-cli download meta-llama/Llama-3.1-8B --local-dir ./base\n          huggingface-cli download ${{ github.repository_owner }}/trained-model --local-dir ./trained\n\n      - name: Run Diagnostics\n        run: |\n          afterburn diagnose \\\n            --base ./base \\\n            --trained ./trained \\\n            --output report.html \\\n            --log-format json \\\n            &gt; diagnostics.log\n\n      - name: Upload Report\n        uses: actions/upload-artifact@v3\n        with:\n          name: afterburn-report\n          path: |\n            report.html\n            diagnostics.log\n\n      - name: Check for Reward Hacking\n        run: |\n          afterburn hack-check \\\n            --base ./base \\\n            --trained ./trained \\\n            --dataset gsm8k \\\n            --threshold 0.15 \\\n            --fail-on-detection\n</code></pre>"},{"location":"guide/deployment/#gitlab-ci-example","title":"GitLab CI Example","text":"<pre><code>afterburn:diagnostics:\n  stage: validate\n  image: python:3.11\n  before_script:\n    - pip install afterburn\n  script:\n    - afterburn diagnose --base $BASE_MODEL --trained $TRAINED_MODEL -o report.html\n  artifacts:\n    paths:\n      - report.html\n    expire_in: 30 days\n  only:\n    - main\n</code></pre>"},{"location":"guide/deployment/#performance-tuning","title":"Performance Tuning","text":""},{"location":"guide/deployment/#cpu-vs-gpu","title":"CPU vs GPU","text":"<p>GPU (Recommended): <pre><code>afterburn diagnose --base base --trained trained -o report.html\n# Uses GPU automatically if available\n</code></pre></p> <p>CPU-only: <pre><code>CUDA_VISIBLE_DEVICES=\"\" afterburn diagnose --base base --trained trained -o report.html\n# Slower but works without GPU\n</code></pre></p>"},{"location":"guide/deployment/#batch-size-tuning","title":"Batch Size Tuning","text":"<p>For behavioral analysis, increase batch size for throughput:</p> <pre><code>afterburn behaviour \\\n  --base base \\\n  --trained trained \\\n  --dataset alpaca \\\n  --batch-size 32  # Default: 16, increase for faster inference\n</code></pre> <p>Guidelines: - T4 / RTX 3060: batch_size = 8-16 - A10 / RTX 4090: batch_size = 16-32 - A100: batch_size = 32-64</p>"},{"location":"guide/deployment/#skip-expensive-modules","title":"Skip Expensive Modules","text":"<p>Speed up analysis by skipping optional modules:</p> <pre><code>afterburn diagnose \\\n  --base base \\\n  --trained trained \\\n  --modules weight_diff behaviour  # Skip semantic, nli, etc.\n  -o report.html\n</code></pre> <p>Module runtime comparison (7B model): - <code>weight_diff</code>: ~2 minutes (always fast) - <code>behaviour</code>: ~10 minutes (depends on dataset size) - <code>reward_hack</code>: ~15 minutes (requires inference) - <code>semantic</code>: ~20 minutes (requires embedding model)</p>"},{"location":"guide/deployment/#disk-io-optimization","title":"Disk I/O Optimization","text":"<p>Cache models on SSD and use local directories:</p> <pre><code># Pre-download models\nhuggingface-cli download meta-llama/Llama-3.1-8B --local-dir /ssd/models/base\n\n# Use local paths\nafterburn diagnose --base /ssd/models/base --trained /ssd/models/trained -o report.html\n</code></pre>"},{"location":"guide/deployment/#monitoring","title":"Monitoring","text":""},{"location":"guide/deployment/#json-log-aggregation","title":"JSON Log Aggregation","text":"<p>Enable JSON logging for structured log ingestion:</p> <pre><code>afterburn diagnose \\\n  --base base \\\n  --trained trained \\\n  --log-format json \\\n  -o report.html \\\n  &gt; afterburn.log 2&gt;&amp;1\n</code></pre> <p>Sample JSON output: <pre><code>{\"timestamp\": \"2026-02-15T14:30:00\", \"level\": \"INFO\", \"logger\": \"afterburn.engine\", \"message\": \"Loading base model\"}\n{\"timestamp\": \"2026-02-15T14:30:15\", \"level\": \"INFO\", \"logger\": \"afterburn.weight_diff\", \"message\": \"Processing layer 5/32\"}\n{\"timestamp\": \"2026-02-15T14:31:00\", \"level\": \"WARNING\", \"logger\": \"afterburn.behaviour\", \"message\": \"High divergence detected in layer 12\"}\n</code></pre></p>"},{"location":"guide/deployment/#elk-stack-integration","title":"ELK Stack Integration","text":"<p>Filebeat configuration: <pre><code>filebeat.inputs:\n  - type: log\n    enabled: true\n    paths:\n      - /var/log/afterburn/*.log\n    json.keys_under_root: true\n    json.add_error_key: true\n\noutput.elasticsearch:\n  hosts: [\"localhost:9200\"]\n  index: \"afterburn-logs-%{+yyyy.MM.dd}\"\n</code></pre></p>"},{"location":"guide/deployment/#cloudwatch-integration","title":"CloudWatch Integration","text":"<pre><code>aws logs create-log-group --log-group-name /afterburn/diagnostics\n\nafterburn diagnose \\\n  --base base \\\n  --trained trained \\\n  --log-format json \\\n  2&gt;&amp;1 | aws logs put-log-events \\\n    --log-group-name /afterburn/diagnostics \\\n    --log-stream-name $(date +%Y%m%d-%H%M%S)\n</code></pre>"},{"location":"guide/deployment/#prometheus-metrics","title":"Prometheus Metrics","text":"<p>Parse JSON logs to extract metrics:</p> <pre><code>import json\n\ndef extract_metrics(log_file):\n    metrics = {\"layer_processing_time\": [], \"warnings\": 0}\n    with open(log_file) as f:\n        for line in f:\n            entry = json.loads(line)\n            if entry[\"level\"] == \"WARNING\":\n                metrics[\"warnings\"] += 1\n            if \"Processing layer\" in entry[\"message\"]:\n                # Extract timing info\n                pass\n    return metrics\n</code></pre>"},{"location":"guide/deployment/#troubleshooting","title":"Troubleshooting","text":""},{"location":"guide/deployment/#out-of-memory-oom","title":"Out of Memory (OOM)","text":"<p>Symptom: Process killed or CUDA OOM error</p> <p>Solutions: 1. Use smaller batch size: <code>--batch-size 8</code> 2. Enable CPU offloading: <code>--device cpu</code> 3. Reduce model precision: Use quantized models (int8) 4. Skip memory-intensive modules: <code>--modules weight_diff</code></p> <p>Example: <pre><code># Low-memory mode\nPYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512 \\\nafterburn diagnose --base base --trained trained --batch-size 4 -o report.html\n</code></pre></p>"},{"location":"guide/deployment/#model-not-found","title":"Model Not Found","text":"<p>Symptom: <code>OSError: meta-llama/Llama-3.1-8B does not exist</code></p> <p>Solutions: 1. Authenticate with HuggingFace: <pre><code>huggingface-cli login\n# or\nexport HF_TOKEN=hf_xxxxx\n</code></pre></p> <ol> <li>Check model name spelling and access permissions</li> <li>Pre-download model: <pre><code>huggingface-cli download meta-llama/Llama-3.1-8B --local-dir ./model\nafterburn diagnose --base ./model --trained trained -o report.html\n</code></pre></li> </ol>"},{"location":"guide/deployment/#huggingface-rate-limiting","title":"HuggingFace Rate Limiting","text":"<p>Symptom: <code>HTTP 429: Too Many Requests</code></p> <p>Solutions: 1. Use HF_TOKEN for authenticated access (higher rate limits) 2. Cache models locally: <pre><code>export HF_HOME=/persistent/cache\n</code></pre> 3. Add retry logic or wait before retrying</p>"},{"location":"guide/deployment/#slow-analysis","title":"Slow Analysis","text":"<p>Symptom: Diagnostics taking hours</p> <p>Quick fixes: 1. Use GPU instead of CPU: Check <code>nvidia-smi</code> 2. Reduce dataset size: <code>--max-samples 100</code> 3. Skip slow modules: <code>--modules weight_diff behaviour</code> 4. Check disk I/O: Use SSD, avoid network mounts</p> <p>Profiling: <pre><code># Enable verbose logging to identify bottlenecks\nafterburn --verbose diagnose --base base --trained trained -o report.html\n</code></pre></p>"},{"location":"guide/deployment/#permission-denied-docker","title":"Permission Denied (Docker)","text":"<p>Symptom: <code>PermissionError: [Errno 13] Permission denied</code></p> <p>Solution: Fix volume permissions: <pre><code># In docker-compose.yml, match user ID\nuser: \"1000:1000\"\n\n# Or fix ownership\ndocker-compose run --rm afterburn chown -R 1000:1000 /app/reports\n</code></pre></p>"},{"location":"guide/deployment/#missing-dependencies","title":"Missing Dependencies","text":"<p>Symptom: <code>ModuleNotFoundError: No module named 'sentence_transformers'</code></p> <p>Solution: Install optional dependencies: <pre><code>pip install afterburn[semantic]  # For semantic analysis\npip install afterburn[pdf]       # For PDF reports\npip install afterburn[nli]       # For NLI analysis\n</code></pre></p>"},{"location":"guide/deployment/#cuda-version-mismatch","title":"CUDA Version Mismatch","text":"<p>Symptom: <code>CUDA driver version is insufficient</code></p> <p>Solution: 1. Check CUDA version: <code>nvidia-smi</code> 2. Install matching PyTorch: <pre><code># For CUDA 11.8\npip install torch --index-url https://download.pytorch.org/whl/cu118\n\n# For CUDA 12.1\npip install torch --index-url https://download.pytorch.org/whl/cu121\n</code></pre></p>"},{"location":"guide/deployment/#report-generation-fails","title":"Report Generation Fails","text":"<p>Symptom: Analysis completes but no report generated</p> <p>Debug: <pre><code># Check write permissions\nls -la report.html\n\n# Use absolute path\nafterburn diagnose --base base --trained trained -o /tmp/report.html\n\n# Check logs for errors\nafterburn --verbose diagnose --base base --trained trained -o report.html\n</code></pre></p>"},{"location":"guide/reports/","title":"Reports","text":""},{"location":"guide/reports/#formats","title":"Formats","text":"Format Command Use Case HTML <code>-o report.html</code> Interactive viewing with Plotly charts JSON <code>-o report.json</code> Pipeline integration, programmatic access Markdown <code>-o report.md</code> Documentation, GitHub issues PDF <code>-o report.pdf</code> Sharing (requires <code>pip install afterburn[pdf]</code>)"},{"location":"guide/reports/#html-report-sections","title":"HTML Report Sections","text":"<ol> <li>Executive Summary \u2014 Key findings in plain English</li> <li>Weight Diff \u2014 Layer heatmap, attention head chart, embedding drift</li> <li>Behavioral Analysis \u2014 Length histograms, strategy distribution, format radar</li> <li>Reward Hacking \u2014 Risk gauge, per-detector scores, sycophancy probes</li> <li>Recommendations \u2014 Actionable next steps</li> </ol>"},{"location":"guide/reward-hacking/","title":"Reward Hacking Detection","text":"<p>Detects common failure modes from RLHF/DPO/GRPO training.</p>"},{"location":"guide/reward-hacking/#detectors","title":"Detectors","text":""},{"location":"guide/reward-hacking/#length-bias","title":"Length Bias","text":"<p>Trained model produces systematically longer outputs without quality gains. Uses paired t-test with Cohen's d effect size.</p>"},{"location":"guide/reward-hacking/#format-gaming","title":"Format Gaming","text":"<p>Model exploits format-based reward signals (always wrapping in code blocks, unnecessary LaTeX). Checks correlation between format usage and answer correctness via ROUGE-L.</p>"},{"location":"guide/reward-hacking/#strategy-collapse","title":"Strategy Collapse","text":"<p>Model converges on a single reasoning strategy, losing diversity. Measured by Shannon entropy drop in strategy distribution.</p>"},{"location":"guide/reward-hacking/#sycophancy","title":"Sycophancy","text":"<p>Model agrees more after training, even with false claims. Three detection methods: 1. Regex-based agreement/pushback rate comparison 2. NLI-enhanced semantic agreement detection 3. 40 adversarial consistency probes across math, science, history, and coding</p>"},{"location":"guide/reward-hacking/#composite-risk-score","title":"Composite Risk Score","text":"<p>Weighted combination (0-100) with confidence adjustment: - Length bias: 25% - Format gaming: 30% - Strategy collapse: 20% - Sycophancy: 25%</p>"},{"location":"guide/weight-diff/","title":"Weight Diff Analysis","text":"<p>Compares model weights layer-by-layer without running inference.</p>"},{"location":"guide/weight-diff/#metrics","title":"Metrics","text":"Metric What It Measures L2 Norm Magnitude of weight change Cosine Similarity Direction preservation (1.0 = unchanged direction) Frobenius Norm Matrix-level change magnitude Relative Change Change normalized by original weight magnitude SVD Decomposition Effective rank, concentration ratio, stable rank of the diff Spectral Alpha Power-law exponent (2-4 = healthy, &gt;6 = overfitting) Marchenko-Pastur Compares eigenvalue spectrum to random matrix theory Behavioral Vectors Principal directions of change via SVD, cross-layer coherence Attention Heads Per-head importance change LayerNorm Shift Gamma/beta parameter drift Embedding Drift Token embedding movement, most-drifted tokens"},{"location":"guide/weight-diff/#memory-efficiency","title":"Memory Efficiency","text":"<p>Uses <code>safetensors.safe_open()</code> for memory-mapped weight access. Never loads both full models simultaneously. Peak memory is ~128MB per layer for 8B models.</p>"},{"location":"guide/weight-diff/#usage","title":"Usage","text":"<pre><code>from afterburn.weight_diff.engine import WeightDiffEngine\nfrom afterburn.device import auto_detect_device\nfrom afterburn.types import ModelPair\n\npair = ModelPair(base_model=\"base-model\", trained_model=\"trained-model\")\nresult = WeightDiffEngine(pair, auto_detect_device()).run()\n\nfor layer in result.top_changed_layers:\n    print(f\"{layer.layer_name}: relative_change={layer.relative_change:.4f}\")\n    if layer.mp_num_spikes is not None:\n        print(f\"  MP spikes: {layer.mp_num_spikes} (bulk: {layer.mp_bulk_fraction:.1%})\")\n\nprint(f\"Direction coherence: {result.direction_coherence:.3f}\")\n</code></pre>"}]}